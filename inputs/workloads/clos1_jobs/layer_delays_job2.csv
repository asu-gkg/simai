input_shapes,input_contiguous,contiguous,output_shape,dtype,Name,meta,_input_nodes,users
[],[],True,"(16, 1024)",torch.int64,input_ids,{},[],"[size, view]"
"[[16, 1024]]",[True],True,"(1,)",,size,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['input_ids'],"[getitem, getitem_2, getitem_3]"
[[1]],[True],True,"(1,)",,getitem,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['size'],[view]
"[[16, 1024], [1]]","[True, True]",True,"(16, 1024)",torch.int64,view,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}","['input_ids', 'getitem']","[size_1, getattr_1, transformer_wte]"
"[[16, 1024]]",[True],True,"(1,)",,size_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['view'],[getitem_1]
[[1]],[True],True,"(1,)",,getitem_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['size_1'],[]
[[1]],[True],True,"(1,)",,getitem_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['size'],[add]
[[1]],[True],True,"(1,)",,add,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['getitem_2'],[arange]
"[[16, 1024]]",[True],True,"(1,)",,getattr_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['view'],[arange]
"[[1], [1]]","[True, True]",True,"(1024,)",torch.int64,arange,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}","['add', 'getattr_1']",[unsqueeze]
[[1024]],[True],True,"(1, 1024)",torch.int64,unsqueeze,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['arange'],[transformer_wpe]
"[[16, 1024]]",[True],True,"(16, 1024, 1280)",torch.float32,transformer_wte,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.wte', ('transformer.wte', <class 'torch.nn.modules.sparse.Embedding'>))])}",['view'],[add_1]
"[[1, 1024]]",[True],True,"(1, 1024, 1280)",torch.float32,transformer_wpe,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.wpe', ('transformer.wpe', <class 'torch.nn.modules.sparse.Embedding'>))])}",['unsqueeze'],[add_1]
"[[16, 1024, 1280], [1, 1024, 1280]]","[True, True]",True,"(16, 1024, 1280)",torch.float32,add_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}","['transformer_wte', 'transformer_wpe']",[transformer_drop]
"[[16, 1024, 1280]]",[True],True,"(16, 1024, 1280)",torch.float32,transformer_drop,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.drop', ('transformer.drop', <class 'torch.nn.modules.dropout.Dropout'>))])}",['add_1'],"[size_2, transformer_h_0_ln_1, add_10]"
[[1]],[True],True,"(1,)",,getitem_3,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['size'],[add_2]
[[1]],[True],True,"(1,)",,add_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['getitem_3'],[add_3]
"[[16, 1024, 1280]]",[True],True,"(1,)",,size_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}",['transformer_drop'],[add_3]
"[[1], [1]]","[True, True]",True,"(1,)",,add_3,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}","['add_2', 'size_2']",[view_13]
"[[16, 1024, 1280]]",[True],True,"(16, 1024, 1280)",torch.float32,transformer_h_0_ln_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.ln_1', ('transformer.h.0.ln_1', <class 'torch.nn.modules.normalization.LayerNorm'>))])}",['transformer_drop'],"[size_3, size_4, view_1]"
"[[16, 1024, 1280]]",[True],True,"(1,)",,size_3,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}",['transformer_h_0_ln_1'],[getitem_4]
[[1]],[True],True,"(1,)",,getitem_4,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}",['size_3'],[add_4]
[[1]],[True],True,"(1,)",,add_4,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}",['getitem_4'],[view_2]
[],[],True,"(3840,)",torch.float32,transformer_h_0_attn_c_attn_bias,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}",[],[addmm]
"[[16, 1024, 1280]]",[True],True,"(1,)",,size_4,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}",['transformer_h_0_ln_1'],[view_1]
"[[16, 1024, 1280], [1]]","[True, True]",True,"(16384, 1280)",torch.float32,view_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}","['transformer_h_0_ln_1', 'size_4']",[addmm]
[],[],True,"(1280, 3840)",torch.float32,transformer_h_0_attn_c_attn_weight,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}",[],[addmm]
"[[3840], [16384, 1280], [1280, 3840]]","[True, True, True]",True,"(16384, 3840)",torch.float32,addmm,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}","['transformer_h_0_attn_c_attn_bias', 'view_1', 'transformer_h_0_attn_c_attn_weight']",[view_2]
"[[16384, 3840], [1]]","[True, True]",True,"(16, 1024, 3840)",torch.float32,view_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_attn', ('transformer.h.0.attn.c_attn', <class 'transformers.pytorch_utils.Conv1D'>))])}","['addmm', 'add_4']",[split]
"[[16, 1024, 3840]]",[True],True,"(1,)",,split,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['view_2'],"[getitem_5, getitem_6, getitem_7]"
[[1]],[True],False,"(16, 1024, 1280)",torch.float32,getitem_5,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['split'],"[size_5, view_3]"
[[1]],[True],False,"(16, 1024, 1280)",torch.float32,getitem_6,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['split'],"[size_6, view_4]"
[[1]],[True],False,"(16, 1024, 1280)",torch.float32,getitem_7,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['split'],"[size_7, view_5]"
"[[16, 1024, 1280]]",[False],True,"(1,)",,size_5,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['getitem_5'],[getitem_8]
[[1]],[True],True,"(1,)",,getitem_8,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['size_5'],[add_5]
[[1]],[True],True,"(1,)",,add_5,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['getitem_8'],[view_3]
"[[16, 1024, 1280], [1]]","[False, True]",False,"(16, 1024, 20, 64)",torch.float32,view_3,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['getitem_5', 'add_5']",[permute]
"[[16, 1024, 20, 64]]",[False],False,"(16, 20, 1024, 64)",torch.float32,permute,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['view_3'],"[matmul, size_9]"
"[[16, 1024, 1280]]",[False],True,"(1,)",,size_6,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['getitem_6'],[getitem_9]
[[1]],[True],True,"(1,)",,getitem_9,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['size_6'],[add_6]
[[1]],[True],True,"(1,)",,add_6,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['getitem_9'],[view_4]
"[[16, 1024, 1280], [1]]","[False, True]",False,"(16, 1024, 20, 64)",torch.float32,view_4,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['getitem_6', 'add_6']",[permute_1]
"[[16, 1024, 20, 64]]",[False],False,"(16, 20, 1024, 64)",torch.float32,permute_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['view_4'],"[transpose, size_10, output]"
"[[16, 1024, 1280]]",[False],True,"(1,)",,size_7,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['getitem_7'],[getitem_10]
[[1]],[True],True,"(1,)",,getitem_10,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['size_7'],[add_7]
[[1]],[True],True,"(1,)",,add_7,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['getitem_10'],[view_5]
"[[16, 1024, 1280], [1]]","[False, True]",False,"(16, 1024, 20, 64)",torch.float32,view_5,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['getitem_7', 'add_7']",[permute_2]
"[[16, 1024, 20, 64]]",[False],False,"(16, 20, 1024, 64)",torch.float32,permute_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['view_5'],"[size_8, getattr_9, matmul_1, output]"
"[[16, 20, 1024, 64]]",[False],False,"(16, 20, 64, 1024)",torch.float32,transpose,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['permute_1'],[matmul]
"[[16, 20, 1024, 64], [16, 20, 64, 1024]]","[False, False]",True,"(16, 20, 1024, 1024)",torch.float32,matmul,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['permute', 'transpose']","[getattr_2, getattr_3, truediv]"
"[[16, 20, 1024, 64]]",[False],True,"(1,)",,size_8,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['permute_2'],[pow_1]
[[1]],[True],True,"(1,)",,pow_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['size_8'],[full]
"[[16, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['matmul'],[full]
"[[16, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_3,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['matmul'],[full]
"[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['pow_1', 'getattr_2', 'getattr_3']",[truediv]
"[[16, 20, 1024, 1024], [1]]","[True, True]",True,"(16, 20, 1024, 1024)",torch.float32,truediv,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['matmul', 'full']","[getattr_4, getattr_6, getattr_7, getattr_8, to]"
"[[16, 20, 1024, 64]]",[False],True,"(1,)",,size_9,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['permute'],[sub]
"[[16, 20, 1024, 64]]",[False],True,"(1,)",,size_10,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['permute_1'],"[sub, getitem_11]"
[],[],True,"(1, 1, 1024, 1024)",torch.bool,transformer_h_0_attn_bias,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",[],[getitem_11]
"[[1], [1]]","[True, True]",True,"(1,)",,sub,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['size_10', 'size_9']",[getitem_11]
"[[1, 1, 1024, 1024], [1], [1]]","[True, True, True]",True,"(1, 1, 1024, 1024)",torch.bool,getitem_11,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['transformer_h_0_attn_bias', 'sub', 'size_10']",[where]
"[[16, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_4,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['truediv'],[finfo]
[[1]],[True],True,"(1,)",,finfo,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['getattr_4'],[getattr_5]
[[1]],[True],True,"(1,)",,getattr_5,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['finfo'],[full_1]
"[[16, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_6,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['truediv'],[full_1]
"[[16, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_7,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['truediv'],[full_1]
"[[1], [1], [1]]","[True, True, True]",True,"(1,)",torch.float32,full_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['getattr_5', 'getattr_6', 'getattr_7']",[where]
"[[16, 20, 1024, 1024]]",[True],True,"(1,)",,getattr_8,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['truediv'],[to]
"[[16, 20, 1024, 1024], [1]]","[True, True]",True,"(16, 20, 1024, 1024)",torch.float32,to,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['truediv', 'getattr_8']",[where]
"[[1, 1, 1024, 1024], [16, 20, 1024, 1024], [1]]","[True, True, True]",True,"(16, 20, 1024, 1024)",torch.float32,where,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['getitem_11', 'to', 'full_1']",[softmax]
"[[16, 20, 1024, 1024]]",[True],True,"(16, 20, 1024, 1024)",torch.float32,softmax,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['where'],[type_1]
"[[16, 20, 1024, 64]]",[False],True,"(1,)",,getattr_9,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['permute_2'],[type_1]
"[[16, 20, 1024, 1024], [1]]","[True, True]",True,"(16, 20, 1024, 1024)",torch.float32,type_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['softmax', 'getattr_9']",[transformer_h_0_attn_attn_dropout]
"[[16, 20, 1024, 1024]]",[True],True,"(16, 20, 1024, 1024)",torch.float32,transformer_h_0_attn_attn_dropout,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.attn_dropout', ('transformer.h.0.attn.attn_dropout', <class 'torch.nn.modules.dropout.Dropout'>))])}",['type_1'],[matmul_1]
"[[16, 20, 1024, 1024], [16, 20, 1024, 64]]","[True, False]",True,"(16, 20, 1024, 64)",torch.float32,matmul_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['transformer_h_0_attn_attn_dropout', 'permute_2']",[permute_3]
"[[16, 20, 1024, 64]]",[True],False,"(16, 1024, 20, 64)",torch.float32,permute_3,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['matmul_1'],[contiguous]
"[[16, 1024, 20, 64]]",[False],True,"(16, 1024, 20, 64)",torch.float32,contiguous,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['permute_3'],"[size_11, view_6]"
"[[16, 1024, 20, 64]]",[True],True,"(1,)",,size_11,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['contiguous'],[getitem_12]
[[1]],[True],True,"(1,)",,getitem_12,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['size_11'],[add_8]
[[1]],[True],True,"(1,)",,add_8,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}",['getitem_12'],[view_6]
"[[16, 1024, 20, 64], [1]]","[True, True]",True,"(16, 1024, 1280)",torch.float32,view_6,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>))])}","['contiguous', 'add_8']","[size_12, size_13, view_7]"
"[[16, 1024, 1280]]",[True],True,"(1,)",,size_12,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",['view_6'],[getitem_13]
[[1]],[True],True,"(1,)",,getitem_13,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",['size_12'],[add_9]
[[1]],[True],True,"(1,)",,add_9,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",['getitem_13'],[view_8]
[],[],True,"(1280,)",torch.float32,transformer_h_0_attn_c_proj_bias,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",[],[addmm_1]
"[[16, 1024, 1280]]",[True],True,"(1,)",,size_13,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",['view_6'],[view_7]
"[[16, 1024, 1280], [1]]","[True, True]",True,"(16384, 1280)",torch.float32,view_7,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}","['view_6', 'size_13']",[addmm_1]
[],[],True,"(1280, 1280)",torch.float32,transformer_h_0_attn_c_proj_weight,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",[],[addmm_1]
"[[1280], [16384, 1280], [1280, 1280]]","[True, True, True]",True,"(16384, 1280)",torch.float32,addmm_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}","['transformer_h_0_attn_c_proj_bias', 'view_7', 'transformer_h_0_attn_c_proj_weight']",[view_8]
"[[16384, 1280], [1]]","[True, True]",True,"(16, 1024, 1280)",torch.float32,view_8,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.c_proj', ('transformer.h.0.attn.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}","['addmm_1', 'add_9']",[transformer_h_0_attn_resid_dropout]
"[[16, 1024, 1280]]",[True],True,"(16, 1024, 1280)",torch.float32,transformer_h_0_attn_resid_dropout,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.attn', ('transformer.h.0.attn', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>)), ('transformer.h.0.attn.resid_dropout', ('transformer.h.0.attn.resid_dropout', <class 'torch.nn.modules.dropout.Dropout'>))])}",['view_8'],[add_10]
"[[16, 1024, 1280], [16, 1024, 1280]]","[True, True]",True,"(16, 1024, 1280)",torch.float32,add_10,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>))])}","['transformer_h_0_attn_resid_dropout', 'transformer_drop']","[transformer_h_0_ln_2, add_15]"
"[[16, 1024, 1280]]",[True],True,"(16, 1024, 1280)",torch.float32,transformer_h_0_ln_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.ln_2', ('transformer.h.0.ln_2', <class 'torch.nn.modules.normalization.LayerNorm'>))])}",['add_10'],"[size_14, size_15, view_9]"
"[[16, 1024, 1280]]",[True],True,"(1,)",,size_14,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}",['transformer_h_0_ln_2'],[getitem_14]
[[1]],[True],True,"(1,)",,getitem_14,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}",['size_14'],[add_11]
[[1]],[True],True,"(1,)",,add_11,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}",['getitem_14'],[view_10]
[],[],True,"(5120,)",torch.float32,transformer_h_0_mlp_c_fc_bias,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}",[],[addmm_2]
"[[16, 1024, 1280]]",[True],True,"(1,)",,size_15,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}",['transformer_h_0_ln_2'],[view_9]
"[[16, 1024, 1280], [1]]","[True, True]",True,"(16384, 1280)",torch.float32,view_9,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}","['transformer_h_0_ln_2', 'size_15']",[addmm_2]
[],[],True,"(1280, 5120)",torch.float32,transformer_h_0_mlp_c_fc_weight,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}",[],[addmm_2]
"[[5120], [16384, 1280], [1280, 5120]]","[True, True, True]",True,"(16384, 5120)",torch.float32,addmm_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}","['transformer_h_0_mlp_c_fc_bias', 'view_9', 'transformer_h_0_mlp_c_fc_weight']",[view_10]
"[[16384, 5120], [1]]","[True, True]",True,"(16, 1024, 5120)",torch.float32,view_10,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_fc', ('transformer.h.0.mlp.c_fc', <class 'transformers.pytorch_utils.Conv1D'>))])}","['addmm_2', 'add_11']","[mul, pow_2, add_12]"
"[[16, 1024, 5120]]",[True],True,"(16, 1024, 5120)",torch.float32,mul,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.act', ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>))])}",['view_10'],[mul_3]
"[[16, 1024, 5120]]",[True],True,"(16, 1024, 5120)",torch.float32,pow_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.act', ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>))])}",['view_10'],[mul_1]
"[[16, 1024, 5120]]",[True],True,"(16, 1024, 5120)",torch.float32,mul_1,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.act', ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>))])}",['pow_2'],[add_12]
"[[16, 1024, 5120], [16, 1024, 5120]]","[True, True]",True,"(16, 1024, 5120)",torch.float32,add_12,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.act', ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>))])}","['view_10', 'mul_1']",[mul_2]
"[[16, 1024, 5120]]",[True],True,"(16, 1024, 5120)",torch.float32,mul_2,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.act', ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>))])}",['add_12'],[tanh]
"[[16, 1024, 5120]]",[True],True,"(16, 1024, 5120)",torch.float32,tanh,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.act', ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>))])}",['mul_2'],[add_13]
"[[16, 1024, 5120]]",[True],True,"(16, 1024, 5120)",torch.float32,add_13,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.act', ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>))])}",['tanh'],[mul_3]
"[[16, 1024, 5120], [16, 1024, 5120]]","[True, True]",True,"(16, 1024, 5120)",torch.float32,mul_3,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.act', ('transformer.h.0.mlp.act', <class 'transformers.activations.NewGELUActivation'>))])}","['mul', 'add_13']","[size_16, size_17, view_11]"
"[[16, 1024, 5120]]",[True],True,"(1,)",,size_16,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",['mul_3'],[getitem_15]
[[1]],[True],True,"(1,)",,getitem_15,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",['size_16'],[add_14]
[[1]],[True],True,"(1,)",,add_14,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",['getitem_15'],[view_12]
[],[],True,"(1280,)",torch.float32,transformer_h_0_mlp_c_proj_bias,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",[],[addmm_3]
"[[16, 1024, 5120]]",[True],True,"(1,)",,size_17,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",['mul_3'],[view_11]
"[[16, 1024, 5120], [1]]","[True, True]",True,"(16384, 5120)",torch.float32,view_11,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}","['mul_3', 'size_17']",[addmm_3]
[],[],True,"(5120, 1280)",torch.float32,transformer_h_0_mlp_c_proj_weight,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}",[],[addmm_3]
"[[1280], [16384, 5120], [5120, 1280]]","[True, True, True]",True,"(16384, 1280)",torch.float32,addmm_3,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}","['transformer_h_0_mlp_c_proj_bias', 'view_11', 'transformer_h_0_mlp_c_proj_weight']",[view_12]
"[[16384, 1280], [1]]","[True, True]",True,"(16, 1024, 1280)",torch.float32,view_12,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.c_proj', ('transformer.h.0.mlp.c_proj', <class 'transformers.pytorch_utils.Conv1D'>))])}","['addmm_3', 'add_14']",[transformer_h_0_mlp_dropout]
"[[16, 1024, 1280]]",[True],True,"(16, 1024, 1280)",torch.float32,transformer_h_0_mlp_dropout,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>)), ('transformer.h.0.mlp', ('transformer.h.0.mlp', <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>)), ('transformer.h.0.mlp.dropout', ('transformer.h.0.mlp.dropout', <class 'torch.nn.modules.dropout.Dropout'>))])}",['view_12'],[add_15]
"[[16, 1024, 1280], [16, 1024, 1280]]","[True, True]",True,"(16, 1024, 1280)",torch.float32,add_15,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.h.0', ('transformer.h.0', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>))])}","['add_10', 'transformer_h_0_mlp_dropout']",[transformer_ln_f]
"[[16, 1024, 1280]]",[True],True,"(16, 1024, 1280)",torch.float32,transformer_ln_f,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>)), ('transformer.ln_f', ('transformer.ln_f', <class 'torch.nn.modules.normalization.LayerNorm'>))])}",['add_15'],[view_13]
"[[16, 1024, 1280], [1]]","[True, True]",True,"(16, 1024, 1280)",torch.float32,view_13,"{'nn_module_stack': OrderedDict([('transformer', ('transformer', <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>))])}","['transformer_ln_f', 'add_3']",[lm_head]
"[[16, 1024, 1280]]",[True],True,"(16, 1024, 50257)",torch.float32,lm_head,"{'nn_module_stack': OrderedDict([('lm_head', ('lm_head', <class 'torch.nn.modules.linear.Linear'>))])}",['view_13'],[output]
"[[16, 1024, 50257], [16, 20, 1024, 64], [16, 20, 1024, 64]]","[True, False, False]",True,"(16, 1024, 50257)",torch.float32,output,{},"['lm_head', 'permute_1', 'permute_2']",[]
